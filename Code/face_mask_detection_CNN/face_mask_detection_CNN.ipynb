{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"face_mask_detection_CNN.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyP1v7bcBiBaJTmHZudl0xB2"},"kernelspec":{"display_name":"Python 3","name":"python3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"ElMOTDU2WXoR"},"source":["# 0. Mount Gdrive"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cr5ZyZDOi8mI","executionInfo":{"status":"ok","timestamp":1607709992975,"user_tz":-540,"elapsed":893,"user":{"displayName":"마스크구분","photoUrl":"","userId":"16417460721574510597"}},"outputId":"1435d950-eef8-48ed-f7af-b0aff263372f"},"source":["# mount drive https://datascience.stackexchange.com/questions/29480/uploading-images-folder-from-my-system-into-google-colab\n","# login with your google account and type authorization code to mount on your google drive.\n","import os\n","from google.colab import drive\n","drive.mount('/gdrive')"],"execution_count":36,"outputs":[{"output_type":"stream","text":["Drive already mounted at /gdrive; to attempt to forcibly remount, call drive.mount(\"/gdrive\", force_remount=True).\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"Y7rrrCr2WcNi"},"source":["# 1. Import library"]},{"cell_type":"code","metadata":{"id":"fOY6oFcdie48","executionInfo":{"status":"ok","timestamp":1607709996106,"user_tz":-540,"elapsed":1394,"user":{"displayName":"마스크구분","photoUrl":"","userId":"16417460721574510597"}}},"source":["import os\n","import zipfile\n","import random\n","import shutil\n","import tensorflow as tf\n","from tensorflow.keras.optimizers import RMSprop\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","from shutil import copyfile\n","from os import getcwd\n","from os import listdir\n","import cv2\n","from tensorflow.keras.layers import Conv2D, Input, ZeroPadding2D, BatchNormalization, Activation, MaxPooling2D, Flatten, Dense\n","from tensorflow.keras.models import Model, load_model\n","from tensorflow.keras.callbacks import TensorBoard, ModelCheckpoint\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import f1_score\n","from sklearn.utils import shuffle\n","import imutils\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import matplotlib.image  as mpimg\n","from PIL import Image\n","from google.colab.patches import cv2_imshow\n","import imutils\n","import math"],"execution_count":37,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"SaZvb_5PWfx4"},"source":["# 2. Define face pre-processing model"]},{"cell_type":"code","metadata":{"id":"EVUZn0iWdIGi","executionInfo":{"status":"ok","timestamp":1607710000040,"user_tz":-540,"elapsed":1315,"user":{"displayName":"마스크구분","photoUrl":"","userId":"16417460721574510597"}}},"source":["# multiple cascades: https://github.com/Itseez/opencv/tree/master/data/haarcascades\n","def extract_mask(SOURCE):\n","    img=cv2.imread(SOURCE)\n","    if img is None:\n","        return []\n","\n","    # load pre-trained Haar cascade model for detect eye point\n","    face_cascade = cv2.CascadeClassifier('/gdrive/My Drive/Code/face_preprocessing/haarcascade_frontalface_default.xml')\n","    eye_cascade = cv2.CascadeClassifier('/gdrive/My Drive/Code/face_preprocessing/haarcascade_eye.xml')\n","\n","    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n","    faces = face_cascade.detectMultiScale(gray, 1.3, 3)\n","\n","    # Append each eye point in the detected face\n","    eye_point = []\n","    for (x,y,w,h) in faces:\n","        roi_gray = gray[y:y+h, x:x+w]\n","        roi_color = img[y:y+h, x:x+w]\n","        \n","        eyes = eye_cascade.detectMultiScale(roi_gray)\n","        eyes = eyes[:2]\n","        for (ex,ey,ew,eh) in eyes:\n","            xx = ex + ew // 2\n","            yy = ey + eh // 2\n","            eye_point.append((x+xx, y+yy))\n","            r = (ew + eh) // 4\n","\n","    # Return empty list if there are no detected eyes\n","    if len(eye_point) < 2:\n","        return []\n","\n","    # Set the left and right eyes by comparing the location\n","    eye1 = eye_point[0]\n","    eye2 = eye_point[1]\n","    length = math.sqrt(((eye1[0] - eye2[0]) ** 2) + ((eye1[1] - eye2[1]) ** 2))\n","\n","    if eye1[0] > eye2[0]:\n","        right = eye1\n","        left = eye2\n","    elif eye1[0] < eye2[0]:\n","        right = eye2\n","        left = eye1\n","\n","    # Rotated the image to fit the eye level\n","    if left[1] > right[1]:\n","        angle = math.atan2((right[1]-left[1]), (right[0]-left[0]))\n","        theta = angle*(180/math.pi);\n","        rotated = imutils.rotate(img,theta)\n","    elif left[1] <= right[1]:\n","        angle = math.atan2((left[1]-right[1]), (right[0]-left[0]))\n","        theta = angle*(180/math.pi);\n","        rotated = imutils.rotate(img,-theta)\n","\n","    # Crop the rotated image by estimated size face\n","    cropped = rotated[int(left[1] - 0.6 * length):int(left[1] + 1.8 * length), int(left[0] - 0.6 * length):int(right[0] + 0.6 * length)]\n","    \n","    if cropped.size == 0:\n","        return []\n","    \n","    # Resize the cropped image by mask region\n","    resized = cv2.resize(cropped, dsize = (120, 140), interpolation=cv2.INTER_AREA)\n","    mask_region = resized[50:, :]\n","\n","    return mask_region"],"execution_count":38,"outputs":[]},{"cell_type":"code","metadata":{"id":"PWCK89Sp7owp","executionInfo":{"status":"ok","timestamp":1607710717945,"user_tz":-540,"elapsed":2566,"user":{"displayName":"마스크구분","photoUrl":"","userId":"16417460721574510597"}}},"source":["def process_data(SOURCE, PROCESS):\n","    dataset=[]\n","\n","    for unitData in os.listdir(SOURCE):\n","        data=SOURCE+unitData\n","        if os.path.getsize(data)>0:\n","            dataset.append(unitData)\n","        else:\n","            print('Skipped '+unitData)\n","            print('Invalid file i.e zero size')\n","    \n","    for unitData in dataset:\n","        temp_set=SOURCE+unitData\n","        final_set=PROCESS+unitData # directory\n","        process_img=extract_mask(temp_set) # img\n","        if process_img==[]:\n","            pass\n","        else:\n","            cv2.imwrite(final_set, process_img)\n","\n","DATA_DIR = \"/gdrive/My Drive/dataset_new/\"\n","PROCESS_DIR = DATA_DIR + \"process/\"\n","\n","YES_SOURCE_DIR = DATA_DIR + \"with_mask/\"\n","YES_PROCESS_DIR = PROCESS_DIR + \"with_mask/\"\n","INCOR_SOURCE_DIR = DATA_DIR + \"incorrect_mask/\"\n","INCOR_PROCESS_DIR = PROCESS_DIR + \"incorrect_mask/\"\n","NO_SOURCE_DIR = DATA_DIR + \"without_mask/\"\n","NO_PROCESS_DIR= PROCESS_DIR + \"without_mask/\""],"execution_count":63,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"C9akRYTdL98u","executionInfo":{"status":"ok","timestamp":1607710006478,"user_tz":-540,"elapsed":1144,"user":{"displayName":"마스크구분","photoUrl":"","userId":"16417460721574510597"}},"outputId":"abedef5e-4ac3-4e15-b147-ab8b864ba003"},"source":["print(\"The number of images with facemask labelled 'yes':\",len(os.listdir(YES_SOURCE_DIR)))\n","print(\"The number of images with facemask labelled 'no':\",len(os.listdir(NO_SOURCE_DIR)))\n","print(\"The number of images with facemask labelled 'incorrect':\",len(os.listdir(INCOR_SOURCE_DIR)))"],"execution_count":40,"outputs":[{"output_type":"stream","text":["The number of images with facemask labelled 'yes': 1916\n","The number of images with facemask labelled 'no': 1919\n","The number of images with facemask labelled 'incorrect': 1987\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pIJc95NtMIDA","executionInfo":{"status":"ok","timestamp":1607710010950,"user_tz":-540,"elapsed":1020,"user":{"displayName":"마스크구분","photoUrl":"","userId":"16417460721574510597"}},"outputId":"5447c8d0-6146-4045-bbc5-95dc8549c268"},"source":["process_data(YES_SOURCE_DIR, YES_PROCESS_DIR)\n","process_data(NO_SOURCE_DIR, NO_PROCESS_DIR)\n","process_data(INCOR_SOURCE_DIR, INCOR_PROCESS_DIR)\n","\n","print(\"The number of images with facemask labelled 'yes':\",len(os.listdir(YES_PROCESS_DIR)))\n","print(\"The number of images with facemask labelled 'no':\",len(os.listdir(NO_PROCESS_DIR)))\n","print(\"The number of images with facemask labelled 'incorrect':\",len(os.listdir(INCOR_PROCESS_DIR)))"],"execution_count":41,"outputs":[{"output_type":"stream","text":["The number of images with facemask labelled 'yes': 85\n","The number of images with facemask labelled 'no': 579\n","The number of images with facemask labelled 'incorrect': 764\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"U2svo2D7kGcQ"},"source":["#3. Split Dataset into Training, Validation, Testing Dataset"]},{"cell_type":"code","metadata":{"id":"8O3mWmoAj1vG","executionInfo":{"status":"ok","timestamp":1607711886225,"user_tz":-540,"elapsed":17641,"user":{"displayName":"마스크구분","photoUrl":"","userId":"16417460721574510597"}}},"source":["def split_data(SOURCE, TRAINING, VALIDATION, SPLIT_SIZE):\n","    dataset = []\n","    \n","    for unitData in os.listdir(SOURCE):\n","        data = SOURCE + unitData\n","        if(os.path.getsize(data) > 0):\n","            dataset.append(unitData)\n","        else:\n","            print('Skipped ' + unitData)\n","            print('Invalid file i.e zero size')\n","    \n","    train_set_length = int(len(dataset) * SPLIT_SIZE)\n","    test_set_length = int(len(dataset) - train_set_length)\n","    train_set = dataset[0:train_set_length]\n","    test_set = dataset[-test_set_length:]\n","       \n","    for unitData in train_set:\n","        temp_train_set = SOURCE + unitData\n","        final_train_set = TRAINING + unitData\n","        copyfile(temp_train_set, final_train_set)\n","    \n","    for unitData in test_set:\n","        temp_valid_set = SOURCE + unitData\n","        final_valid_set = VALIDATION + unitData\n","        copyfile(temp_valid_set, final_valid_set)\n","\n","TRAINING_DIR = DATA_DIR + \"training/\"\n","VALIDATION_DIR = DATA_DIR + \"validation/\"\n","TESTING_DIR = DATA_DIR + \"testing/\"\n","\n","TRAINING_YES_DIR = TRAINING_DIR + \"with_mask/\"\n","VALIDATION_YES_DIR = VALIDATION_DIR + \"with_mask/\"\n","TESTING_YES_DIR = TESTING_DIR + \"with_mask/\"\n","\n","TRAINING_INCOR_DIR = TRAINING_DIR + \"incorrect_mask/\"\n","VALIDATION_INCOR_DIR = VALIDATION_DIR + \"incorrect_mask/\"\n","TESTING_INCOR_DIR = TESTING_DIR + \"incorrect_mask/\"\n","\n","TRAINING_NO_DIR = TRAINING_DIR + \"without_mask/\"\n","VALIDATION_NO_DIR = VALIDATION_DIR + \"without_mask/\"\n","TESTING_NO_DIR = TESTING_DIR + \"without_mask/\"\n","split_size = .8\n","\n","# split datasets into training set and testing set\n","split_data(YES_PROCESS_DIR, TRAINING_YES_DIR, VALIDATION_YES_DIR, split_size)\n","split_data(INCOR_PROCESS_DIR, TRAINING_INCOR_DIR, VALIDATION_INCOR_DIR, split_size)\n","split_data(NO_PROCESS_DIR, TRAINING_NO_DIR, VALIDATION_NO_DIR, split_size)"],"execution_count":108,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"N1_rsxrmphTQ","executionInfo":{"status":"ok","timestamp":1607711445880,"user_tz":-540,"elapsed":1001,"user":{"displayName":"마스크구분","photoUrl":"","userId":"16417460721574510597"}},"outputId":"c8d8d4f8-e71c-49ca-f721-01f31d60d5a1"},"source":["print(\"The number of images with facemask in the training set labelled 'with_mask':\", len(os.listdir(TRAINING_YES_DIR)))\n","print(\"The number of images with facemask in the validation set labelled 'with_mask':\", len(os.listdir(VALIDATION_YES_DIR)))\n","print(\"The number of images with facemask in the test set labelled 'with_mask':\", len(os.listdir(TESTING_YES_DIR)))\n","\n","print(\"The number of images without facemask in the training set labelled 'incorrect_mask':\", len(os.listdir(TRAINING_INCOR_DIR)))\n","print(\"The number of images with facemask in the validation set labelled 'incorrect_mask':\", len(os.listdir(VALIDATION_INCOR_DIR)))\n","print(\"The number of images without facemask in the test set labelled 'incorrect_mask':\", len(os.listdir(TESTING_INCOR_DIR)))\n","\n","print(\"The number of images without facemask in the training set labelled 'without_mask':\", len(os.listdir(TRAINING_NO_DIR)))\n","print(\"The number of images with facemask in the validation set labelled 'without_mask':\", len(os.listdir(VALIDATION_NO_DIR)))\n","print(\"The number of images without facemask in the test set labelled 'without_mask':\", len(os.listdir(TESTING_NO_DIR)))"],"execution_count":91,"outputs":[{"output_type":"stream","text":["The number of images with facemask in the training set labelled 'with_mask': 68\n","The number of images with facemask in the validation set labelled 'with_mask': 17\n","The number of images with facemask in the test set labelled 'with_mask': 0\n","The number of images without facemask in the training set labelled 'incorrect_mask': 0\n","The number of images with facemask in the validation set labelled 'incorrect_mask': 0\n","The number of images without facemask in the test set labelled 'incorrect_mask': 153\n","The number of images without facemask in the training set labelled 'without_mask': 0\n","The number of images with facemask in the validation set labelled 'without_mask': 0\n","The number of images without facemask in the test set labelled 'without_mask': 116\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"mp4xOllYkNKL"},"source":["#4. Make CNN Model"]},{"cell_type":"markdown","metadata":{"id":"SEHQO_a9kPhv"},"source":["##4.1. One CNN model with 3 Classes"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"s78A7aSGp2Hc","executionInfo":{"status":"ok","timestamp":1607710254990,"user_tz":-540,"elapsed":1526,"user":{"displayName":"마스크구분","photoUrl":"","userId":"16417460721574510597"}},"outputId":"a5e5d500-7069-4784-a1d0-f4c203dd9d31"},"source":["model=tf.keras.models.Sequential([\n","    tf.keras.layers.Conv2D(32, (5, 5), activation='relu', input_shape=(90, 120, 3)),\n","    tf.keras.layers.MaxPooling2D(2, 2),\n","\n","    tf.keras.layers.Conv2D(128, (5, 5), activation='relu'),\n","    tf.keras.layers.MaxPooling2D(2, 2),\n","\n","    # 2차원 array pixel을 1차원 array로 변환\n","    tf.keras.layers.Flatten(),\n","    tf.keras.layers.Dropout(0.5),\n","    # 128개의 node 층\n","    tf.keras.layers.Dense(128, activation='relu'),\n","    # 출력층은 한 개의 node로 구성되고 0-1 사의의 값을 출력\n","    tf.keras.layers.Dense(3, activation='softmax')\n","])\n","\n","model.summary()"],"execution_count":46,"outputs":[{"output_type":"stream","text":["Model: \"sequential_3\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","conv2d_6 (Conv2D)            (None, 86, 116, 32)       2432      \n","_________________________________________________________________\n","max_pooling2d_6 (MaxPooling2 (None, 43, 58, 32)        0         \n","_________________________________________________________________\n","conv2d_7 (Conv2D)            (None, 39, 54, 128)       102528    \n","_________________________________________________________________\n","max_pooling2d_7 (MaxPooling2 (None, 19, 27, 128)       0         \n","_________________________________________________________________\n","flatten_3 (Flatten)          (None, 65664)             0         \n","_________________________________________________________________\n","dropout_3 (Dropout)          (None, 65664)             0         \n","_________________________________________________________________\n","dense_6 (Dense)              (None, 128)               8405120   \n","_________________________________________________________________\n","dense_7 (Dense)              (None, 3)                 387       \n","=================================================================\n","Total params: 8,510,467\n","Trainable params: 8,510,467\n","Non-trainable params: 0\n","_________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"5EFocGDdz8Au","executionInfo":{"status":"ok","timestamp":1607710257524,"user_tz":-540,"elapsed":915,"user":{"displayName":"마스크구분","photoUrl":"","userId":"16417460721574510597"}}},"source":["model.compile(optimizer='adam',\n","              loss='binary_crossentropy',\n","              # metrics: training 단계와 test 단계를 모니터링 하기 위해 사용, 해당 코드에서는 올바른 이미지의 비율인 accuracy를 사용\n","              metrics=['accuracy'])"],"execution_count":47,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"P7xU2NmT4USD","executionInfo":{"status":"ok","timestamp":1607711895388,"user_tz":-540,"elapsed":1019,"user":{"displayName":"마스크구분","photoUrl":"","userId":"16417460721574510597"}},"outputId":"7affe2d0-3895-458d-9e45-1491eb1ebf50"},"source":["# 값을 0-1 사이로 조정\n","train_datagen=ImageDataGenerator(rescale=1.0/255)\n","train_generator=train_datagen.flow_from_directory(TRAINING_DIR, \n","                                                  batch_size=10, \n","                                                  target_size=(90, 120))\n","\n","validation_datagen=ImageDataGenerator(rescale=1.0/255)\n","validation_generator=validation_datagen.flow_from_directory(VALIDATION_DIR, \n","                                                  batch_size=10, \n","                                                  target_size=(90, 120))\n","\n","testing_datagen=ImageDataGenerator(rescale=1.0/255)\n","testing_generator=testing_datagen.flow_from_directory(TESTING_DIR, \n","                                                  batch_size=10, \n","                                                  target_size=(90, 120))"],"execution_count":109,"outputs":[{"output_type":"stream","text":["Found 1142 images belonging to 3 classes.\n","Found 286 images belonging to 3 classes.\n","Found 286 images belonging to 3 classes.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"zzpcuunx57eU","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1607710345946,"user_tz":-540,"elapsed":77161,"user":{"displayName":"마스크구분","photoUrl":"","userId":"16417460721574510597"}},"outputId":"31b01d72-d07d-4b2d-865b-abd08d10cd16"},"source":["hitory=model.fit_generator(train_generator,\n","                           epochs=30, \n","                           validation_data=validation_generator)"],"execution_count":49,"outputs":[{"output_type":"stream","text":["Epoch 1/30\n","115/115 [==============================] - 3s 29ms/step - loss: 0.2752 - accuracy: 0.8765 - val_loss: 0.1287 - val_accuracy: 0.9406\n","Epoch 2/30\n","115/115 [==============================] - 3s 22ms/step - loss: 0.0918 - accuracy: 0.9588 - val_loss: 0.0878 - val_accuracy: 0.9650\n","Epoch 3/30\n","115/115 [==============================] - 2s 21ms/step - loss: 0.0814 - accuracy: 0.9641 - val_loss: 0.1129 - val_accuracy: 0.9720\n","Epoch 4/30\n","115/115 [==============================] - 2s 22ms/step - loss: 0.0771 - accuracy: 0.9597 - val_loss: 0.0819 - val_accuracy: 0.9685\n","Epoch 5/30\n","115/115 [==============================] - 2s 21ms/step - loss: 0.0725 - accuracy: 0.9650 - val_loss: 0.0784 - val_accuracy: 0.9790\n","Epoch 6/30\n","115/115 [==============================] - 3s 22ms/step - loss: 0.0476 - accuracy: 0.9772 - val_loss: 0.0797 - val_accuracy: 0.9755\n","Epoch 7/30\n","115/115 [==============================] - 2s 20ms/step - loss: 0.0331 - accuracy: 0.9825 - val_loss: 0.1036 - val_accuracy: 0.9825\n","Epoch 8/30\n","115/115 [==============================] - 2s 21ms/step - loss: 0.0392 - accuracy: 0.9816 - val_loss: 0.0931 - val_accuracy: 0.9790\n","Epoch 9/30\n","115/115 [==============================] - 2s 21ms/step - loss: 0.0250 - accuracy: 0.9895 - val_loss: 0.1249 - val_accuracy: 0.9755\n","Epoch 10/30\n","115/115 [==============================] - 2s 21ms/step - loss: 0.0248 - accuracy: 0.9895 - val_loss: 0.1469 - val_accuracy: 0.9615\n","Epoch 11/30\n","115/115 [==============================] - 3s 27ms/step - loss: 0.0112 - accuracy: 0.9930 - val_loss: 0.1448 - val_accuracy: 0.9685\n","Epoch 12/30\n","115/115 [==============================] - 2s 21ms/step - loss: 0.0296 - accuracy: 0.9886 - val_loss: 0.1412 - val_accuracy: 0.9650\n","Epoch 13/30\n","115/115 [==============================] - 2s 21ms/step - loss: 0.0918 - accuracy: 0.9711 - val_loss: 0.1176 - val_accuracy: 0.9685\n","Epoch 14/30\n","115/115 [==============================] - 2s 21ms/step - loss: 0.0543 - accuracy: 0.9790 - val_loss: 0.1541 - val_accuracy: 0.9336\n","Epoch 15/30\n","115/115 [==============================] - 2s 21ms/step - loss: 0.1376 - accuracy: 0.9606 - val_loss: 0.1944 - val_accuracy: 0.9371\n","Epoch 16/30\n","115/115 [==============================] - 2s 21ms/step - loss: 0.0333 - accuracy: 0.9904 - val_loss: 0.1126 - val_accuracy: 0.9755\n","Epoch 17/30\n","115/115 [==============================] - 2s 21ms/step - loss: 0.0169 - accuracy: 0.9939 - val_loss: 0.1261 - val_accuracy: 0.9685\n","Epoch 18/30\n","115/115 [==============================] - 2s 21ms/step - loss: 0.0089 - accuracy: 0.9939 - val_loss: 0.1338 - val_accuracy: 0.9720\n","Epoch 19/30\n","115/115 [==============================] - 2s 21ms/step - loss: 0.0163 - accuracy: 0.9947 - val_loss: 0.1280 - val_accuracy: 0.9650\n","Epoch 20/30\n","115/115 [==============================] - 2s 21ms/step - loss: 0.0109 - accuracy: 0.9947 - val_loss: 0.1663 - val_accuracy: 0.9650\n","Epoch 21/30\n","115/115 [==============================] - 2s 21ms/step - loss: 0.0041 - accuracy: 0.9991 - val_loss: 0.1669 - val_accuracy: 0.9650\n","Epoch 22/30\n","115/115 [==============================] - 3s 22ms/step - loss: 0.0024 - accuracy: 0.9991 - val_loss: 0.1723 - val_accuracy: 0.9650\n","Epoch 23/30\n","115/115 [==============================] - 2s 21ms/step - loss: 0.1018 - accuracy: 0.9685 - val_loss: 0.1052 - val_accuracy: 0.9685\n","Epoch 24/30\n","115/115 [==============================] - 2s 21ms/step - loss: 0.0378 - accuracy: 0.9842 - val_loss: 0.1171 - val_accuracy: 0.9720\n","Epoch 25/30\n","115/115 [==============================] - 2s 21ms/step - loss: 0.0220 - accuracy: 0.9921 - val_loss: 0.1121 - val_accuracy: 0.9580\n","Epoch 26/30\n","115/115 [==============================] - 2s 22ms/step - loss: 0.0309 - accuracy: 0.9860 - val_loss: 0.1385 - val_accuracy: 0.9545\n","Epoch 27/30\n","115/115 [==============================] - 2s 21ms/step - loss: 0.0245 - accuracy: 0.9921 - val_loss: 0.1413 - val_accuracy: 0.9441\n","Epoch 28/30\n","115/115 [==============================] - 2s 21ms/step - loss: 0.0077 - accuracy: 0.9956 - val_loss: 0.1606 - val_accuracy: 0.9615\n","Epoch 29/30\n","115/115 [==============================] - 2s 21ms/step - loss: 0.0019 - accuracy: 0.9991 - val_loss: 0.1997 - val_accuracy: 0.9650\n","Epoch 30/30\n","115/115 [==============================] - 2s 21ms/step - loss: 0.0176 - accuracy: 0.9947 - val_loss: 0.1868 - val_accuracy: 0.9545\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"CYDDBpL0BYHq"},"source":["model.save('/gdrive/My Drive/Code/face_mask_detection_CNN/saved_incor_model')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"g-ZGZ284Dg7Y","executionInfo":{"status":"ok","timestamp":1607711900961,"user_tz":-540,"elapsed":1954,"user":{"displayName":"마스크구분","photoUrl":"","userId":"16417460721574510597"}},"outputId":"b9d26a32-aa55-423f-b014-51d88c32694f"},"source":["new_model=tf.keras.models.load_model('/gdrive/My Drive/Code/face_mask_detection_CNN/saved_incor_model')\n","\n","new_model.summary()"],"execution_count":110,"outputs":[{"output_type":"stream","text":["Model: \"sequential\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","conv2d (Conv2D)              (None, 86, 116, 32)       2432      \n","_________________________________________________________________\n","max_pooling2d (MaxPooling2D) (None, 43, 58, 32)        0         \n","_________________________________________________________________\n","conv2d_1 (Conv2D)            (None, 39, 54, 128)       102528    \n","_________________________________________________________________\n","max_pooling2d_1 (MaxPooling2 (None, 19, 27, 128)       0         \n","_________________________________________________________________\n","flatten (Flatten)            (None, 65664)             0         \n","_________________________________________________________________\n","dropout (Dropout)            (None, 65664)             0         \n","_________________________________________________________________\n","dense (Dense)                (None, 128)               8405120   \n","_________________________________________________________________\n","dense_1 (Dense)              (None, 3)                 387       \n","=================================================================\n","Total params: 8,510,467\n","Trainable params: 8,510,467\n","Non-trainable params: 0\n","_________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"igAb3eKtI5eL","executionInfo":{"status":"ok","timestamp":1607711904998,"user_tz":-540,"elapsed":2255,"user":{"displayName":"마스크구분","photoUrl":"","userId":"16417460721574510597"}},"outputId":"08f17d4a-1cad-4332-8d3e-56ad884fd531"},"source":["results=new_model.evaluate(testing_generator)\n","for name, value in zip(new_model.metrics_names, results):\n","    print(\"%s: %.3f\" %(name, value))"],"execution_count":111,"outputs":[{"output_type":"stream","text":["29/29 [==============================] - 0s 16ms/step - loss: 0.0901 - accuracy: 0.9720\n","loss: 0.090\n","accuracy: 0.972\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"5JSON1sIk2aY"},"source":["##4.2. Two CNN Models with 2 Classes"]},{"cell_type":"markdown","metadata":{"id":"kQZh8jH4k6uG"},"source":["###4.2.1. Classifying With mask and Without mask"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"EvJMw4WAlNaB","executionInfo":{"status":"ok","timestamp":1607710413476,"user_tz":-540,"elapsed":1030,"user":{"displayName":"마스크구분","photoUrl":"","userId":"16417460721574510597"}},"outputId":"5cd23da2-4216-467e-8f4a-eb1d694850fe"},"source":["model=tf.keras.models.Sequential([\n","    tf.keras.layers.Conv2D(32, (5, 5), activation='relu', input_shape=(90, 120, 3)),\n","    tf.keras.layers.MaxPooling2D(2, 2),\n","\n","    tf.keras.layers.Conv2D(128, (5, 5), activation='relu'),\n","    tf.keras.layers.MaxPooling2D(2, 2),\n","\n","    # 2차원 array pixel을 1차원 array로 변환\n","    tf.keras.layers.Flatten(),\n","    tf.keras.layers.Dropout(0.5),\n","    # 128개의 node 층\n","    tf.keras.layers.Dense(128, activation='relu'),\n","    # 출력층은 한 개의 node로 구성되고 0-1 사의의 값을 출력\n","    tf.keras.layers.Dense(2, activation='softmax')\n","])\n","\n","model.summary()"],"execution_count":51,"outputs":[{"output_type":"stream","text":["Model: \"sequential_4\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","conv2d_8 (Conv2D)            (None, 86, 116, 32)       2432      \n","_________________________________________________________________\n","max_pooling2d_8 (MaxPooling2 (None, 43, 58, 32)        0         \n","_________________________________________________________________\n","conv2d_9 (Conv2D)            (None, 39, 54, 128)       102528    \n","_________________________________________________________________\n","max_pooling2d_9 (MaxPooling2 (None, 19, 27, 128)       0         \n","_________________________________________________________________\n","flatten_4 (Flatten)          (None, 65664)             0         \n","_________________________________________________________________\n","dropout_4 (Dropout)          (None, 65664)             0         \n","_________________________________________________________________\n","dense_8 (Dense)              (None, 128)               8405120   \n","_________________________________________________________________\n","dense_9 (Dense)              (None, 2)                 258       \n","=================================================================\n","Total params: 8,510,338\n","Trainable params: 8,510,338\n","Non-trainable params: 0\n","_________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Oyq9NLoilQsH","executionInfo":{"status":"ok","timestamp":1607710415934,"user_tz":-540,"elapsed":850,"user":{"displayName":"마스크구분","photoUrl":"","userId":"16417460721574510597"}}},"source":["model.compile(optimizer='adam',\n","              loss='binary_crossentropy',\n","              # metrics: training 단계와 test 단계를 모니터링 하기 위해 사용, 해당 코드에서는 올바른 이미지의 비율인 accuracy를 사용\n","              metrics=['accuracy'])"],"execution_count":52,"outputs":[]},{"cell_type":"code","metadata":{"id":"MeS2dUS3lViS","executionInfo":{"status":"ok","timestamp":1607711647471,"user_tz":-540,"elapsed":10059,"user":{"displayName":"마스크구분","photoUrl":"","userId":"16417460721574510597"}}},"source":["TRAINING_DIR = DATA_DIR + \"training2/\"\n","VALIDATION_DIR = DATA_DIR + \"validation2/\"\n","TESTING_DIR = DATA_DIR + \"testing2/\"\n","\n","TRAINING_YES_DIR = TRAINING_DIR + \"with_mask/\"\n","VALIDATION_YES_DIR = VALIDATION_DIR + \"with_mask/\"\n","TESTING_YES_DIR = TESTING_DIR + \"with_mask/\"\n","\n","TRAINING_NO_DIR = TRAINING_DIR + \"without_mask/\"\n","VALIDATION_NO_DIR = VALIDATION_DIR + \"without_mask/\"\n","TESTING_NO_DIR = TESTING_DIR + \"without_mask/\"\n","split_size = .8\n","\n","# split datasets into training set and testing set\n","split_data(YES_PROCESS_DIR, TRAINING_YES_DIR, VALIDATION_YES_DIR, split_size)\n","split_data(NO_PROCESS_DIR, TRAINING_NO_DIR, VALIDATION_NO_DIR, split_size)"],"execution_count":100,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"b3arO30rlTFV","executionInfo":{"status":"ok","timestamp":1607711763439,"user_tz":-540,"elapsed":1401,"user":{"displayName":"마스크구분","photoUrl":"","userId":"16417460721574510597"}},"outputId":"5be90250-d88f-48a9-fa05-3010f2226a40"},"source":["# 값을 0-1 사이로 조정\n","train_datagen=ImageDataGenerator(rescale=1.0/255)\n","train_generator=train_datagen.flow_from_directory(TRAINING_DIR, \n","                                                  batch_size=10, \n","                                                  target_size=(90, 120))\n","\n","validation_datagen=ImageDataGenerator(rescale=1.0/255)\n","validation_generator=validation_datagen.flow_from_directory(VALIDATION_DIR, \n","                                                  batch_size=10, \n","                                                  target_size=(90, 120))\n","\n","testing_datagen=ImageDataGenerator(rescale=1.0/255)\n","testing_generator=testing_datagen.flow_from_directory(TESTING_DIR, \n","                                                  batch_size=10, \n","                                                  target_size=(90, 120))"],"execution_count":101,"outputs":[{"output_type":"stream","text":["Found 531 images belonging to 2 classes.\n","Found 133 images belonging to 2 classes.\n","Found 112 images belonging to 2 classes.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"RU0IHE5lmYPA","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1607710615765,"user_tz":-540,"elapsed":39766,"user":{"displayName":"마스크구분","photoUrl":"","userId":"16417460721574510597"}},"outputId":"19127e21-3581-4fc5-97e6-3c6d417a8853"},"source":["hitory=model.fit_generator(train_generator,\n","                           epochs=30, \n","                           validation_data=validation_generator)"],"execution_count":57,"outputs":[{"output_type":"stream","text":["Epoch 1/30\n","54/54 [==============================] - 1s 25ms/step - loss: 0.4479 - accuracy: 0.8418 - val_loss: 0.3907 - val_accuracy: 0.9023\n","Epoch 2/30\n","54/54 [==============================] - 1s 26ms/step - loss: 0.1434 - accuracy: 0.9492 - val_loss: 0.1879 - val_accuracy: 0.9699\n","Epoch 3/30\n","54/54 [==============================] - 1s 21ms/step - loss: 0.1324 - accuracy: 0.9567 - val_loss: 0.1227 - val_accuracy: 0.9549\n","Epoch 4/30\n","54/54 [==============================] - 1s 21ms/step - loss: 0.1180 - accuracy: 0.9642 - val_loss: 0.1687 - val_accuracy: 0.9474\n","Epoch 5/30\n","54/54 [==============================] - 1s 21ms/step - loss: 0.1447 - accuracy: 0.9623 - val_loss: 0.1704 - val_accuracy: 0.9624\n","Epoch 6/30\n","54/54 [==============================] - 1s 21ms/step - loss: 0.1183 - accuracy: 0.9661 - val_loss: 0.1414 - val_accuracy: 0.9624\n","Epoch 7/30\n","54/54 [==============================] - 1s 21ms/step - loss: 0.1431 - accuracy: 0.9586 - val_loss: 0.3338 - val_accuracy: 0.9098\n","Epoch 8/30\n","54/54 [==============================] - 1s 22ms/step - loss: 0.0933 - accuracy: 0.9718 - val_loss: 0.1761 - val_accuracy: 0.9624\n","Epoch 9/30\n","54/54 [==============================] - 1s 22ms/step - loss: 0.0688 - accuracy: 0.9812 - val_loss: 0.2098 - val_accuracy: 0.9624\n","Epoch 10/30\n","54/54 [==============================] - 1s 22ms/step - loss: 0.0591 - accuracy: 0.9831 - val_loss: 0.1728 - val_accuracy: 0.9699\n","Epoch 11/30\n","54/54 [==============================] - 1s 22ms/step - loss: 0.0728 - accuracy: 0.9755 - val_loss: 0.1986 - val_accuracy: 0.9624\n","Epoch 12/30\n","54/54 [==============================] - 1s 21ms/step - loss: 0.1979 - accuracy: 0.9567 - val_loss: 0.3035 - val_accuracy: 0.9323\n","Epoch 13/30\n","54/54 [==============================] - 1s 22ms/step - loss: 0.1001 - accuracy: 0.9642 - val_loss: 0.1328 - val_accuracy: 0.9549\n","Epoch 14/30\n","54/54 [==============================] - 1s 22ms/step - loss: 0.0809 - accuracy: 0.9793 - val_loss: 0.2239 - val_accuracy: 0.9549\n","Epoch 15/30\n","54/54 [==============================] - 1s 22ms/step - loss: 0.0641 - accuracy: 0.9887 - val_loss: 0.2109 - val_accuracy: 0.9549\n","Epoch 16/30\n","54/54 [==============================] - 1s 22ms/step - loss: 0.0947 - accuracy: 0.9774 - val_loss: 0.2133 - val_accuracy: 0.9624\n","Epoch 17/30\n","54/54 [==============================] - 1s 21ms/step - loss: 0.0513 - accuracy: 0.9906 - val_loss: 0.1171 - val_accuracy: 0.9699\n","Epoch 18/30\n","54/54 [==============================] - 1s 21ms/step - loss: 0.1116 - accuracy: 0.9793 - val_loss: 0.2026 - val_accuracy: 0.9098\n","Epoch 19/30\n","54/54 [==============================] - 1s 22ms/step - loss: 0.1339 - accuracy: 0.9699 - val_loss: 0.2173 - val_accuracy: 0.9474\n","Epoch 20/30\n","54/54 [==============================] - 1s 24ms/step - loss: 0.0384 - accuracy: 0.9868 - val_loss: 0.1695 - val_accuracy: 0.9699\n","Epoch 21/30\n","54/54 [==============================] - 2s 34ms/step - loss: 0.0366 - accuracy: 0.9944 - val_loss: 0.1521 - val_accuracy: 0.9774\n","Epoch 22/30\n","54/54 [==============================] - 1s 22ms/step - loss: 0.0403 - accuracy: 0.9944 - val_loss: 0.1622 - val_accuracy: 0.9699\n","Epoch 23/30\n","54/54 [==============================] - 1s 23ms/step - loss: 0.0628 - accuracy: 0.9831 - val_loss: 0.1432 - val_accuracy: 0.9624\n","Epoch 24/30\n","54/54 [==============================] - 1s 22ms/step - loss: 0.0529 - accuracy: 0.9812 - val_loss: 0.2239 - val_accuracy: 0.9474\n","Epoch 25/30\n","54/54 [==============================] - 1s 21ms/step - loss: 0.0586 - accuracy: 0.9831 - val_loss: 0.1989 - val_accuracy: 0.9624\n","Epoch 26/30\n","54/54 [==============================] - 1s 24ms/step - loss: 0.0814 - accuracy: 0.9831 - val_loss: 0.1266 - val_accuracy: 0.9624\n","Epoch 27/30\n","54/54 [==============================] - 1s 22ms/step - loss: 0.0462 - accuracy: 0.9887 - val_loss: 0.1243 - val_accuracy: 0.9624\n","Epoch 28/30\n","54/54 [==============================] - 1s 21ms/step - loss: 0.0618 - accuracy: 0.9868 - val_loss: 0.1246 - val_accuracy: 0.9699\n","Epoch 29/30\n","54/54 [==============================] - 1s 26ms/step - loss: 0.0363 - accuracy: 0.9962 - val_loss: 0.1258 - val_accuracy: 0.9699\n","Epoch 30/30\n","54/54 [==============================] - 1s 22ms/step - loss: 0.0600 - accuracy: 0.9812 - val_loss: 0.1628 - val_accuracy: 0.9699\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"7XkNH51VnHBn","executionInfo":{"status":"ok","timestamp":1607710624837,"user_tz":-540,"elapsed":1027,"user":{"displayName":"마스크구분","photoUrl":"","userId":"16417460721574510597"}}},"source":["model.save('/gdrive/My Drive/Code/face_mask_detection_CNN/saved_new_model')"],"execution_count":58,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ks89-uB_m-kK","executionInfo":{"status":"ok","timestamp":1607711771885,"user_tz":-540,"elapsed":1683,"user":{"displayName":"마스크구분","photoUrl":"","userId":"16417460721574510597"}},"outputId":"403f2859-2299-4eb7-fd12-b9ad4e43f394"},"source":["new_model=tf.keras.models.load_model('/gdrive/My Drive/Code/face_mask_detection_CNN/saved_new_model')\n","\n","new_model.summary()"],"execution_count":102,"outputs":[{"output_type":"stream","text":["Model: \"sequential_2\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","conv2d_4 (Conv2D)            (None, 86, 116, 32)       2432      \n","_________________________________________________________________\n","max_pooling2d_4 (MaxPooling2 (None, 43, 58, 32)        0         \n","_________________________________________________________________\n","conv2d_5 (Conv2D)            (None, 39, 54, 128)       102528    \n","_________________________________________________________________\n","max_pooling2d_5 (MaxPooling2 (None, 19, 27, 128)       0         \n","_________________________________________________________________\n","flatten_2 (Flatten)          (None, 65664)             0         \n","_________________________________________________________________\n","dropout_2 (Dropout)          (None, 65664)             0         \n","_________________________________________________________________\n","dense_4 (Dense)              (None, 128)               8405120   \n","_________________________________________________________________\n","dense_5 (Dense)              (None, 2)                 258       \n","=================================================================\n","Total params: 8,510,338\n","Trainable params: 8,510,338\n","Non-trainable params: 0\n","_________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xl-OgmFimbYL","executionInfo":{"status":"ok","timestamp":1607711796103,"user_tz":-540,"elapsed":23703,"user":{"displayName":"마스크구분","photoUrl":"","userId":"16417460721574510597"}},"outputId":"01984602-93a3-4f9b-a5a7-ff9c887bb6b1"},"source":["results=new_model.evaluate(testing_generator)\n","for name, value in zip(new_model.metrics_names, results):\n","    print(\"%s: %.3f\" %(name, value))"],"execution_count":103,"outputs":[{"output_type":"stream","text":["12/12 [==============================] - 21s 2s/step - loss: 0.0402 - accuracy: 0.9911\n","loss: 0.040\n","accuracy: 0.991\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"MJL1YG6rlA0N"},"source":["###4.2.2 Classifying Incorrect mask and Without mask"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2PRJQa0dncR8","executionInfo":{"status":"ok","timestamp":1607711082438,"user_tz":-540,"elapsed":1480,"user":{"displayName":"마스크구분","photoUrl":"","userId":"16417460721574510597"}},"outputId":"093cc8a7-6667-4f09-f6ce-c1a20aaf3d29"},"source":["model=tf.keras.models.Sequential([\n","    tf.keras.layers.Conv2D(32, (5, 5), activation='relu', input_shape=(90, 120, 3)),\n","    tf.keras.layers.MaxPooling2D(2, 2),\n","\n","    tf.keras.layers.Conv2D(128, (5, 5), activation='relu'),\n","    tf.keras.layers.MaxPooling2D(2, 2),\n","\n","    # 2차원 array pixel을 1차원 array로 변환\n","    tf.keras.layers.Flatten(),\n","    tf.keras.layers.Dropout(0.5),\n","    # 128개의 node 층\n","    tf.keras.layers.Dense(128, activation='relu'),\n","    # 출력층은 한 개의 node로 구성되고 0-1 사의의 값을 출력\n","    tf.keras.layers.Dense(2, activation='softmax')\n","])\n","\n","model.summary()"],"execution_count":82,"outputs":[{"output_type":"stream","text":["Model: \"sequential_8\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","conv2d_16 (Conv2D)           (None, 86, 116, 32)       2432      \n","_________________________________________________________________\n","max_pooling2d_16 (MaxPooling (None, 43, 58, 32)        0         \n","_________________________________________________________________\n","conv2d_17 (Conv2D)           (None, 39, 54, 128)       102528    \n","_________________________________________________________________\n","max_pooling2d_17 (MaxPooling (None, 19, 27, 128)       0         \n","_________________________________________________________________\n","flatten_8 (Flatten)          (None, 65664)             0         \n","_________________________________________________________________\n","dropout_8 (Dropout)          (None, 65664)             0         \n","_________________________________________________________________\n","dense_16 (Dense)             (None, 128)               8405120   \n","_________________________________________________________________\n","dense_17 (Dense)             (None, 2)                 258       \n","=================================================================\n","Total params: 8,510,338\n","Trainable params: 8,510,338\n","Non-trainable params: 0\n","_________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"ADM1Laajnhpk","executionInfo":{"status":"ok","timestamp":1607711086139,"user_tz":-540,"elapsed":1024,"user":{"displayName":"마스크구분","photoUrl":"","userId":"16417460721574510597"}}},"source":["model.compile(optimizer='adam',\n","              loss='binary_crossentropy',\n","              # metrics: training 단계와 test 단계를 모니터링 하기 위해 사용, 해당 코드에서는 올바른 이미지의 비율인 accuracy를 사용\n","              metrics=['accuracy'])"],"execution_count":83,"outputs":[]},{"cell_type":"code","metadata":{"id":"xLGFdL-5njF-","executionInfo":{"status":"ok","timestamp":1607711827801,"user_tz":-540,"elapsed":16713,"user":{"displayName":"마스크구분","photoUrl":"","userId":"16417460721574510597"}}},"source":["TRAINING_DIR = DATA_DIR + \"training3/\"\n","VALIDATION_DIR = DATA_DIR + \"validation3/\"\n","TESTING_DIR = DATA_DIR + \"testing3/\"\n","\n","TRAINING_INCOR_DIR = TRAINING_DIR + \"incorrect_mask/\"\n","VALIDATION_INCOR_DIR = VALIDATION_DIR + \"incorrect_mask/\"\n","TESTING_INCOR_DIR = TESTING_DIR + \"incorrect_mask/\"\n","\n","TRAINING_NO_DIR = TRAINING_DIR + \"without_mask/\"\n","VALIDATION_NO_DIR = VALIDATION_DIR + \"without_mask/\"\n","TESTING_NO_DIR = TESTING_DIR + \"without_mask/\"\n","split_size = .8\n","\n","# split datasets into training set and testing set\n","split_data(INCOR_PROCESS_DIR, TRAINING_INCOR_DIR, VALIDATION_INCOR_DIR, split_size)\n","split_data(NO_PROCESS_DIR, TRAINING_NO_DIR, VALIDATION_NO_DIR, split_size)"],"execution_count":104,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HSeOLJ4XoF5Q","executionInfo":{"status":"ok","timestamp":1607711830424,"user_tz":-540,"elapsed":1177,"user":{"displayName":"마스크구분","photoUrl":"","userId":"16417460721574510597"}},"outputId":"33cb1e85-cc69-4961-fb23-fef1410feb2f"},"source":["# 값을 0-1 사이로 조정\n","train_datagen=ImageDataGenerator(rescale=1.0/255)\n","train_generator=train_datagen.flow_from_directory(TRAINING_DIR, \n","                                                  batch_size=10, \n","                                                  target_size=(90, 120))\n","\n","validation_datagen=ImageDataGenerator(rescale=1.0/255)\n","validation_generator=validation_datagen.flow_from_directory(VALIDATION_DIR, \n","                                                  batch_size=10, \n","                                                  target_size=(90, 120))\n","\n","testing_datagen=ImageDataGenerator(rescale=1.0/255)\n","testing_generator=testing_datagen.flow_from_directory(TESTING_DIR, \n","                                                  batch_size=10, \n","                                                  target_size=(90, 120))"],"execution_count":105,"outputs":[{"output_type":"stream","text":["Found 1074 images belonging to 2 classes.\n","Found 269 images belonging to 2 classes.\n","Found 269 images belonging to 2 classes.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7yyaiTjXohKN","executionInfo":{"status":"ok","timestamp":1607711281440,"user_tz":-540,"elapsed":74089,"user":{"displayName":"마스크구분","photoUrl":"","userId":"16417460721574510597"}},"outputId":"5f3a8e3b-4c01-486c-d816-029d8815cabe"},"source":["hitory=model.fit_generator(train_generator,\n","                           epochs=30, \n","                           validation_data=validation_generator)"],"execution_count":88,"outputs":[{"output_type":"stream","text":["Epoch 1/30\n","108/108 [==============================] - 3s 25ms/step - loss: 0.1981 - accuracy: 0.9534 - val_loss: 0.0682 - val_accuracy: 0.9777\n","Epoch 2/30\n","108/108 [==============================] - 2s 22ms/step - loss: 0.0532 - accuracy: 0.9907 - val_loss: 0.0744 - val_accuracy: 0.9926\n","Epoch 3/30\n","108/108 [==============================] - 2s 23ms/step - loss: 0.0560 - accuracy: 0.9851 - val_loss: 0.0591 - val_accuracy: 0.9814\n","Epoch 4/30\n","108/108 [==============================] - 2s 21ms/step - loss: 0.5322 - accuracy: 0.9544 - val_loss: 4.9493 - val_accuracy: 0.6654\n","Epoch 5/30\n","108/108 [==============================] - 2s 23ms/step - loss: 0.5574 - accuracy: 0.9507 - val_loss: 0.1053 - val_accuracy: 0.9814\n","Epoch 6/30\n","108/108 [==============================] - 2s 23ms/step - loss: 0.0452 - accuracy: 0.9888 - val_loss: 0.0842 - val_accuracy: 0.9926\n","Epoch 7/30\n","108/108 [==============================] - 2s 23ms/step - loss: 0.3176 - accuracy: 0.9758 - val_loss: 0.3845 - val_accuracy: 0.9740\n","Epoch 8/30\n","108/108 [==============================] - 2s 21ms/step - loss: 0.4225 - accuracy: 0.9693 - val_loss: 0.0033 - val_accuracy: 0.9963\n","Epoch 9/30\n","108/108 [==============================] - 2s 21ms/step - loss: 0.1327 - accuracy: 0.9907 - val_loss: 0.0406 - val_accuracy: 0.9963\n","Epoch 10/30\n","108/108 [==============================] - 2s 21ms/step - loss: 0.1627 - accuracy: 0.9870 - val_loss: 0.2296 - val_accuracy: 0.9814\n","Epoch 11/30\n","108/108 [==============================] - 2s 21ms/step - loss: 0.0613 - accuracy: 0.9898 - val_loss: 0.1601 - val_accuracy: 0.9851\n","Epoch 12/30\n","108/108 [==============================] - 2s 22ms/step - loss: 0.0542 - accuracy: 0.9926 - val_loss: 0.0717 - val_accuracy: 0.9851\n","Epoch 13/30\n","108/108 [==============================] - 2s 22ms/step - loss: 0.0264 - accuracy: 0.9953 - val_loss: 0.3221 - val_accuracy: 0.9628\n","Epoch 14/30\n","108/108 [==============================] - 2s 22ms/step - loss: 0.0748 - accuracy: 0.9898 - val_loss: 0.0781 - val_accuracy: 0.9888\n","Epoch 15/30\n","108/108 [==============================] - 2s 22ms/step - loss: 0.0268 - accuracy: 0.9944 - val_loss: 0.0909 - val_accuracy: 0.9888\n","Epoch 16/30\n","108/108 [==============================] - 3s 25ms/step - loss: 0.0207 - accuracy: 0.9981 - val_loss: 0.0902 - val_accuracy: 0.9888\n","Epoch 17/30\n","108/108 [==============================] - 2s 21ms/step - loss: 0.0162 - accuracy: 0.9981 - val_loss: 0.0920 - val_accuracy: 0.9888\n","Epoch 18/30\n","108/108 [==============================] - 2s 21ms/step - loss: 0.0155 - accuracy: 0.9991 - val_loss: 0.0892 - val_accuracy: 0.9888\n","Epoch 19/30\n","108/108 [==============================] - 2s 22ms/step - loss: 0.0194 - accuracy: 0.9972 - val_loss: 0.0942 - val_accuracy: 0.9888\n","Epoch 20/30\n","108/108 [==============================] - 2s 22ms/step - loss: 0.0205 - accuracy: 0.9981 - val_loss: 0.0849 - val_accuracy: 0.9851\n","Epoch 21/30\n","108/108 [==============================] - 2s 23ms/step - loss: 0.0214 - accuracy: 0.9963 - val_loss: 0.1003 - val_accuracy: 0.9851\n","Epoch 22/30\n","108/108 [==============================] - 2s 22ms/step - loss: 0.0156 - accuracy: 0.9981 - val_loss: 0.0995 - val_accuracy: 0.9888\n","Epoch 23/30\n","108/108 [==============================] - 3s 24ms/step - loss: 0.0152 - accuracy: 0.9991 - val_loss: 0.1042 - val_accuracy: 0.9851\n","Epoch 24/30\n","108/108 [==============================] - 2s 23ms/step - loss: 0.0146 - accuracy: 0.9991 - val_loss: 0.1138 - val_accuracy: 0.9851\n","Epoch 25/30\n","108/108 [==============================] - 2s 22ms/step - loss: 0.0149 - accuracy: 0.9991 - val_loss: 0.0950 - val_accuracy: 0.9888\n","Epoch 26/30\n","108/108 [==============================] - 2s 22ms/step - loss: 0.0147 - accuracy: 0.9991 - val_loss: 0.0916 - val_accuracy: 0.9851\n","Epoch 27/30\n","108/108 [==============================] - 2s 23ms/step - loss: 0.0144 - accuracy: 0.9991 - val_loss: 0.0940 - val_accuracy: 0.9851\n","Epoch 28/30\n","108/108 [==============================] - 2s 21ms/step - loss: 0.0144 - accuracy: 0.9991 - val_loss: 0.0950 - val_accuracy: 0.9851\n","Epoch 29/30\n","108/108 [==============================] - 2s 21ms/step - loss: 0.0143 - accuracy: 0.9991 - val_loss: 0.0950 - val_accuracy: 0.9851\n","Epoch 30/30\n","108/108 [==============================] - 2s 22ms/step - loss: 0.0143 - accuracy: 0.9991 - val_loss: 0.0953 - val_accuracy: 0.9851\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"hWAhsathoosv","executionInfo":{"status":"ok","timestamp":1607711289357,"user_tz":-540,"elapsed":1061,"user":{"displayName":"마스크구분","photoUrl":"","userId":"16417460721574510597"}}},"source":["model.save('/gdrive/My Drive/Code/face_mask_detection_CNN/class2_model')"],"execution_count":89,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bfLhFAwHwA90","executionInfo":{"status":"ok","timestamp":1607711836809,"user_tz":-540,"elapsed":1620,"user":{"displayName":"마스크구분","photoUrl":"","userId":"16417460721574510597"}},"outputId":"ed1b5244-e272-4aa9-a909-4e805a42062a"},"source":["new_model=tf.keras.models.load_model('/gdrive/My Drive/Code/face_mask_detection_CNN/class2_model')\n","\n","new_model.summary()"],"execution_count":106,"outputs":[{"output_type":"stream","text":["Model: \"sequential_2\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","conv2d_4 (Conv2D)            (None, 86, 116, 32)       2432      \n","_________________________________________________________________\n","max_pooling2d_4 (MaxPooling2 (None, 43, 58, 32)        0         \n","_________________________________________________________________\n","conv2d_5 (Conv2D)            (None, 39, 54, 128)       102528    \n","_________________________________________________________________\n","max_pooling2d_5 (MaxPooling2 (None, 19, 27, 128)       0         \n","_________________________________________________________________\n","flatten_2 (Flatten)          (None, 65664)             0         \n","_________________________________________________________________\n","dropout_2 (Dropout)          (None, 65664)             0         \n","_________________________________________________________________\n","dense_4 (Dense)              (None, 128)               8405120   \n","_________________________________________________________________\n","dense_5 (Dense)              (None, 2)                 258       \n","=================================================================\n","Total params: 8,510,338\n","Trainable params: 8,510,338\n","Non-trainable params: 0\n","_________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"n_NbXAnPwEh1","executionInfo":{"status":"ok","timestamp":1607711839832,"user_tz":-540,"elapsed":1594,"user":{"displayName":"마스크구분","photoUrl":"","userId":"16417460721574510597"}},"outputId":"826e5ebc-16c6-45a0-8929-f5e0140e16c8"},"source":["results=new_model.evaluate(testing_generator)\n","for name, value in zip(new_model.metrics_names, results):\n","    print(\"%s: %.3f\" %(name, value))"],"execution_count":107,"outputs":[{"output_type":"stream","text":["27/27 [==============================] - 0s 15ms/step - loss: 0.1039 - accuracy: 0.9888\n","loss: 0.104\n","accuracy: 0.989\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"WHLOFgFnlKsF"},"source":["#5. Video to Frame"]},{"cell_type":"code","metadata":{"id":"vA45RCld8yus"},"source":["def video2frame(invideofilename, save_path):\n","    vidcap = cv2.VideoCapture(invideofilename)\n","    count = 0\n","    while True:\n","      success,image = vidcap.read()\n","      if not success:\n","          break\n","      fname = \"{}.jpg\".format(\"{0:05d}\".format(count))\n","      cv2.imwrite(save_path + fname, image) # save frame as JPEG file\n","      count += 1\n","    print(\"{} images are extracted in {}.\". format(count, save_path))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Q_QX8a2J89oD"},"source":["invideofilename = '/gdrive/My Drive/jisu_mp4.mp4'\n","save_path = '/gdrive/My Drive/mp4_capture/'\n","video2frame(invideofilename,save_path)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"3yRH3Nh49fhj"},"source":["for i in range(509):\n","    img_string = '/gdrive/My Drive/mp4_capture/{0:05d}.jpg'.format(i)\n","    img=extract_mask(img_string)\n","    img=(np.expand_dims(img, 0))\n","\n","    # predictions_single=model.predict(img)\n","    # np.argmax(predictions_single[0])\n","    print(\"{0:05d}:\".format(i), end = \" \")\n","    try:\n","        predictions_single=new_model.predict(img)\n","    except:\n","        print(\"\")\n","        continue\n","    print(np.argmax(predictions_single[0]))"],"execution_count":null,"outputs":[]}]}